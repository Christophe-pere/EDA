{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Exploratory Data Analysis (EDA)</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h2><i>Tabular data</i></h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is made to permit users to explore quickly their data. The goal is to automatize this part of the lifecycle to provide insights and intuitions about the data. So the notebook uses pandas-profiling, and dataprep.eda to facilitate the exploration. Next, the different parts explore the feature importance and feature extraction with different methods and algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Content</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Sand box to load and clean data](#part_0)\n",
    "- [I - EDA](#part_1)\n",
    "    - [I-1 pandas-profiling](#part_1_1)\n",
    "    - [I-2 Dataprep EDA](#part_1_2)\n",
    "    - [I-3 Target identification](#part_1_3)\n",
    "- [II - Feature selection](#part_2)\n",
    "    - [II-1 Removing features with low variance](#part_2_1)\n",
    "    - [II-2 Univariate Selection](#part_2_2)\n",
    "    - [II-3 Recursive Feature Elimination (RFE)](#part_2_3)\n",
    "- [III - Feature Extraction](#part_3)\n",
    "    - [III-1 Principal Component Analysis (PCA)](#part_3_1)\n",
    "    - [III-2 Independent Component Analysis (ICA)](#part_3_2)\n",
    "    - [III-3 Linear Discriminant Analysis (LDA)](#part_3_3)\n",
    "    - [III-4 Locally Linear Embedding (LLE)](#part_3_4)\n",
    "    - [III-5 t-distributed Stochastic Neighbor Embedding (t-SNE)](#part_3_5)\n",
    "- [VI - Feature Importance](#part_4)\n",
    "    - [VI-1 Tree method](#part_4_1)\n",
    "    - [VI-2 Permutation Method](#part_4_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"part_0\">Sand box to load and clean data</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rfpimp \n",
    "#!pip install eli5\n",
    "#!pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#importing all the libraries\n",
    "from dataprep.eda import plot, plot_correlation, plot_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the boston housing prices to test the pipe\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "df = pd.DataFrame(X_train)\n",
    "df.loc[:, \"target\"] = y_train\n",
    "df_= pd.DataFrame(X_test)\n",
    "df_.loc[:, \"target\"] = y_test\n",
    "df = df.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"part_1\">I - EDA</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"part_1_1\">I-1 Pandas-profiling</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title='Pandas Profiling Report', explorative=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the results in widget\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the html inside the notebook\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"part_1_2\">I-2 Dataprep EDA</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Plot\n",
    "plot(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Correlation\n",
    "plot_correlation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API Missing Value\n",
    "plot_missing(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><a id=\"part_1_3\">I-3 Target identification</a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, ~df.columns.isin([TARGET])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = False\n",
    "if y.dtype==float:\n",
    "    print(\"The data is continuous\")\n",
    "    continuous=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"part_2\">II - Feature Selection</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_2_1\">Removing features with low variance</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove feature containing more than 80% of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "X_variance = sel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The new number of features is: {X_variance.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_2_2\">Univariate Selection</a></u></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The univariate Selection is done with the chi square approach. The goal of this approach is to seelect features with the strongest relationships with the output variable.\n",
    "\n",
    "In the scikit-learn package, the function to do that is <a href=https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html>SelectKBest</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not continuous:\n",
    "    from sklearn.feature_selection import SelectKBest\n",
    "    from sklearn.feature_selection import chi2\n",
    "\n",
    "    #apply SelectKBest class to extract top 10 best features\n",
    "    bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "    fit = bestfeatures.fit(X,y)\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    #concat two dataframes for better visualization \n",
    "    featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "    featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "    print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_2_3\">Recursive Feature Elimination (RFE)</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>SVM</b></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not continuous:\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    # The \"accuracy\" scoring is proportional to the number of correct\n",
    "    # classifications\n",
    "    rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
    "                  scoring='accuracy')\n",
    "    rfecv.fit(X, y)\n",
    "\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i><b>Logistic Regression</b></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction with RFE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not continuous:\n",
    "    # feature extraction\n",
    "    model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "    rfe = RFE(model, 3)\n",
    "    fit = rfe.fit(X, Y)\n",
    "    print(\"Num Features: %d\" % fit.n_features_)\n",
    "    print(\"Selected Features: %s\" % fit.support_)\n",
    "    print(\"Feature Ranking: %s\" % fit.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"part_3\">III - Feature Extraction</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_3_1\">Principle Component Analysis (PCA)</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_var = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=N_var)\n",
    "X_pca = pca.fit_transform(X)\n",
    "df_pca = pd.DataFrame(data = X_pca, columns = ['PC1', 'PC2'])\n",
    "#df_pca.loc[:, TARGET]=df.loc[:, TARGET]\n",
    "#df_pca[TARGET] = LabelEncoder().fit_transform(df_pca[TARGET])\n",
    "#df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(df_pca[\"PC1\"],df_pca[\"PC2\"], \".\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_3_2\">Independent Component Analysis (ICA)</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = FastICA(n_components=N_var)\n",
    "X_ica = ica.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(X_ica[:, 0],X_ica[:,1], \".\")\n",
    "plt.xlabel(\"ICA0\")\n",
    "plt.ylabel(\"ICA1\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_3_3\">Linear Discriminant Analysis (LDA)</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not continuous:\n",
    "    lda = LinearDiscriminantAnalysis(n_components=N_var)\n",
    "\n",
    "    # run an LDA and use it to transform the features\n",
    "    X_lda = lda.fit(X, y).transform(X)\n",
    "    print('Original number of features:', X.shape[1])\n",
    "    print('Reduced number of features:', X_lda.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_3_4\">Locally Linear Embedding (LLE)</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import locally_linear_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle, error = locally_linear_embedding(X, n_neighbors=5, n_components=N_var, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The squarred error is: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(lle[:, 0], lle[:, 1],  cmap=plt.cm.Spectral)\n",
    "plt.xlabel(\"lle0\")\n",
    "plt.ylabel(\"lle1\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_3_5\">t-distributed Stochastic Neighbor Embedding (t-SNE)</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=N_var).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1],  cmap=plt.cm.Spectral)\n",
    "plt.xlabel(\"t-SNE0\")\n",
    "plt.ylabel(\"t-SNE1\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><a id=\"part_4\">VI - Feature Importance</a></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_4_1\">Tree method</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not continuous:\n",
    "    # Build a forest and compute the impurity-based feature importances\n",
    "    forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                                  random_state=0)\n",
    "\n",
    "    forest.fit(X, y)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the impurity-based feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "            color=\"b\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continuous:\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators = 100,\n",
    "                               n_jobs = -1,\n",
    "                               oob_score = True,\n",
    "                               bootstrap = True,\n",
    "                               random_state = 42)\n",
    "    rf.fit(X, y)\n",
    "\n",
    "    print('R^2 Training Score: {:.2f} \\nOOB Score: {:.2f} '.format(rf.score(X, y), rf.oob_score_,))\n",
    "\n",
    "    results = pd.DataFrame(data=rf.feature_importances_, index=X.columns)\n",
    "    results.columns = [\"Importance\"]\n",
    "    results.sort_values(by=[\"Importance\"], ascending=False)\n",
    "    importances = rf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                 axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(results.index, results.Importance,\n",
    "            color=\"b\", yerr=std, align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><u><a id=\"part_4_2\">Permutation Method</a></u></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continuous:\n",
    "    from sklearn.metrics import r2_score\n",
    "    from rfpimp import permutation_importances\n",
    "\n",
    "    def r2(rf, X_train, y_train):\n",
    "        return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "    perm_imp_rfpimp = permutation_importances(rf, X, y, r2)\n",
    "    importances = perm_imp_rfpimp.Importance\n",
    "    \n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(results.index, results.Importance,\n",
    "                color=\"b\",  align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if continuous:\n",
    "    import eli5\n",
    "    from eli5.sklearn import PermutationImportance\n",
    "\n",
    "    perm = PermutationImportance(rf, cv = None, refit = False, n_iter = 50).fit(X, y)\n",
    "    results = pd.DataFrame(data= perm.feature_importances_, index=X.columns)\n",
    "    results.columns = [\"Importance\"]\n",
    "    results.sort_values(by=[\"Importance\"], ascending=False)\n",
    "    importances = perm.feature_importances_\n",
    "    #std = np.std([tree.feature_importances_ for tree in perm.estimators_],\n",
    "    #             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(results.index, results.Importance,\n",
    "                color=\"b\",  align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "anaconda-project-anaconda201908_py37-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
